{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84103193-380b-4f68-a33d-9c706d1f4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c017f6d",
   "metadata": {},
   "source": [
    "## Functions for Calculate consensus & accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676721f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_consensus(message_embeddings, isc=False):\n",
    "    # message_embedding: [num_text X text_vector]\n",
    "    if isc:\n",
    "        #consensus method2: ISC\n",
    "        corr_ls=[]\n",
    "        for sub in range(message_embeddings.shape[0]):\n",
    "            sub_vec=message_embeddings[sub]\n",
    "            rest_vec=message_embeddings[~np.isin(np.arange(len(message_embeddings)), sub)]\n",
    "            avg_rest_vec=np.mean(rest_vec,axis=0)\n",
    "            corr=np.inner(sub_vec,avg_rest_vec)\n",
    "            corr_ls.append(corr)\n",
    "        return np.mean(corr_ls)\n",
    "    else:\n",
    "        #consensus method1: average of similartiy matrix\n",
    "        return np.nanmean(np.inner(message_embeddings,message_embeddings))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1d52bf2-d6e9-4e8a-8310-01fb9e6c1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_avg_description(prediction_offset):\n",
    "    if prediction_offset<10:\n",
    "        return np.nan\n",
    "    description_file =  f'../../Cleaned Data/Description_Cleaned_Data/{film}_description_cleaned.csv'\n",
    "    embedding_folder = '../../Cleaned Data/Description_Cleaned_Data/embedding'\n",
    "    df=pd.read_csv(description_file)\n",
    "    data_description=df[df['phase_type']=='test']\n",
    "    \n",
    "    description_row=data_description[data_description['onset']==prediction_offset]\n",
    "    description_c=str(int(description_row['counterbalance'].iloc[0]))\n",
    "    description_seg=str(int(description_row['description_stop'].iloc[0]))\n",
    "    filename=f\"{embedding_folder}/{film}/{film}_test_c{description_c}_seg{description_seg}.npy\"\n",
    "    description_embed=np.load(filename)\n",
    "    avg_desc_embed=np.nanmean(description_embed,axis=0)\n",
    "    return avg_desc_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72887866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(prediction_embed,avg_desc_embed):\n",
    "    cos_ls=[]\n",
    "    for sub in range(prediction_embed.shape[0]):\n",
    "        sub_vec=prediction_embed[sub]\n",
    "        cos=np.inner(sub_vec,avg_desc_embed)\n",
    "        cos_ls.append(cos)\n",
    "    accuracy=np.mean(cos_ls)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894da723",
   "metadata": {},
   "source": [
    "## prediction\n",
    "calculate prediction consensus, accuracy, confidence for each prediction stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc1c7319-200f-4c36-a69c-a096bfef02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ls=['theshoe','therock','theboyfriend','keithreynolds','cmiyc_long','busstop']\n",
    "#film_ls=['theshoe']\n",
    "for film in film_ls:\n",
    "    filename=f'../../Cleaned Data/Prediction_Cleaned_Data/{film}_prediction_cleaned.csv'\n",
    "    embedding_folder = '../../Cleaned Data/Prediction_Cleaned_Data/embedding'\n",
    "    df=pd.read_csv(filename)\n",
    "    # Filter for test phase\n",
    "    df_test = df[df['phase_type'] == 'test']\n",
    "    \n",
    "    results = []\n",
    "    # Loop through each group of counterbalance and video_segment\n",
    "    for (c, seg), group in df_test.groupby(['counterbalance', 'video_segment']):\n",
    "        # Path to the saved embedding file\n",
    "        file_path = f\"{embedding_folder}/{film}/{film}_test_c{c}_seg{seg}.npy\"\n",
    "    \n",
    "        # Load embeddings\n",
    "        message_embeddings = np.load(file_path)\n",
    "    \n",
    "        # Get offset (unique within each group)\n",
    "        offset = group['offset'].iloc[0]\n",
    "        \n",
    "        # Number of responses\n",
    "        n_response = len(group)\n",
    "        n_subj = group['ID'].nunique()\n",
    "\n",
    "        # Average confidence\n",
    "        confidence=group['confidence'].mean()\n",
    "        # Calculate consensus \n",
    "        consensus_isc = calc_consensus(message_embeddings)\n",
    "        \n",
    "        # Calculate accuracy by comparing prediction to description\n",
    "        avg_desc = obtain_avg_description(offset)\n",
    "        accuracy=calc_accuracy(message_embeddings,avg_desc)\n",
    "\n",
    "        # Append result\n",
    "        results.append({\n",
    "            \"counterbalance\": c,\n",
    "            \"offset\": offset,\n",
    "            \"video_segment\": seg,\n",
    "            \"n_response\": n_response,\n",
    "            \"n_subj\":n_subj,\n",
    "            \"consensus_isc\": consensus_isc,\n",
    "            \"accuracy\":accuracy,\n",
    "            \"confidence\":confidence\n",
    "        })\n",
    "    \n",
    "    # Create the result DataFrame\n",
    "    df_consensus = pd.DataFrame(results)\n",
    "        \n",
    "    output_path=f'../../Analysis Data/Prediction/{film}_prediction_accuracy_consensus_summary.csv'\n",
    "    df_consensus.to_csv(output_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a33fe",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12b49269-acc7-4ad9-8529-e51670df31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ls=['theshoe','therock','theboyfriend','keithreynolds','cmiyc_long','busstop']\n",
    "for film in film_ls:\n",
    "    filename=f'../../Cleaned Data/Description_Cleaned_Data/{film}_description_cleaned.csv'\n",
    "    embedding_folder = '../../Cleaned Data/Description_Cleaned_Data/embedding'\n",
    "    df=pd.read_csv(filename)\n",
    "    # Filter for test phase\n",
    "    df_test = df[df['phase_type'] == 'test']\n",
    "    \n",
    "    results = []\n",
    "    # Loop through each group of counterbalance and video_segment\n",
    "    for (c, seg), group in df_test.groupby(['counterbalance', 'description_stop']):\n",
    "        # Path to the saved embedding file\n",
    "        file_path = f\"{embedding_folder}/{film}/{film}_test_c{c}_seg{seg}.npy\"\n",
    "    \n",
    "        # Load embeddings\n",
    "        message_embeddings = np.load(file_path)\n",
    "    \n",
    "        # Get offset (unique within each group)\n",
    "        offset = group['offset'].iloc[0]\n",
    "        onset = group['onset'].iloc[0]\n",
    "\n",
    "        # Number of subject\n",
    "        n_subj = group['ID'].nunique()\n",
    "\n",
    "        # Average importance\n",
    "        importance=group['importance'].mean()\n",
    "        # Calculate consensus \n",
    "        consensus_isc = calc_consensus(message_embeddings)\n",
    "        \n",
    "        # Append result\n",
    "        results.append({\n",
    "            \"counterbalance\": c,\n",
    "            \"onset\":onset,\n",
    "            \"offset\": offset,\n",
    "            \"description_stop\": seg,\n",
    "            \"n_subj\":n_subj,\n",
    "            \"consensus_isc\": consensus_isc,\n",
    "            \"importance\":importance\n",
    "        })\n",
    "    \n",
    "    # Create the result DataFrame\n",
    "    df_consensus = pd.DataFrame(results)\n",
    "        \n",
    "    output_path=f'../../Analysis Data/Description/{film}_description_consensus_summary.csv'\n",
    "    df_consensus.to_csv(output_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09067253",
   "metadata": {},
   "source": [
    "# map movie timestamp to brain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e397b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_tr(second,onset=True,prediction=True):\n",
    "    if onset: \n",
    "        if  prediction and (second['video_segment'] == '1' or  second['video_segment'] == 'Title'):\n",
    "            return round(second['filmfest_onset']/1.5)\n",
    "        else:\n",
    "            try:\n",
    "                return round(second['filmfest_onset']/1.5)+1\n",
    "            except:\n",
    "                return round(second['filmfest_onset30']/1.5)+1\n",
    "    if not onset:\n",
    "        return round(second/1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48c889f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_start={'busstop':948,'cmiyc_long':40,'keithreynolds':1134,'theboyfriend':528,'therock':40,'theshoe':999}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33597f23",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4074749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ls=['theshoe','therock','theboyfriend','keithreynolds','cmiyc_long','busstop']\n",
    "for film in film_ls:\n",
    "    folder=f'../../Analysis Data/Prediction'\n",
    "    data=pd.read_csv(f'{folder}/{film}_prediction_accuracy_consensus_summary.csv')\n",
    "    data=data.sort_values(by='offset')\n",
    "    #find offset and onset of each video in the filmfest moive\n",
    "    data['filmfest_offset']=data['offset'].apply(lambda x:x+movie_start[film])\n",
    "    data['filmfest_onset']=data['filmfest_offset'].apply(lambda x: x-10 if x>(10+movie_start[film]) else movie_start[film])\n",
    "    data['TR_onset']=data[['filmfest_onset','video_segment']].apply(lambda x: seconds_to_tr(x,onset=True),axis=1)\n",
    "    data['TR_offset']=data['filmfest_offset'].apply(lambda x: seconds_to_tr(x,onset=False))\n",
    "    output_path=f'{folder}/{film}_consensus_mapped_to_neuro.csv'\n",
    "    data.to_csv(output_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62947a9b",
   "metadata": {},
   "source": [
    "## description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "664b71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ls=['therock','theshoe','theboyfriend','keithreynolds','cmiyc_long','busstop']\n",
    "for film in film_ls:\n",
    "    folder=f'../../Analysis Data/Description'\n",
    "    data=pd.read_csv(f'{folder}/{film}_description_consensus_summary.csv')\n",
    "    data=data.sort_values(by='offset')\n",
    "    #find offset and onset of each video in the filmfest moive\n",
    "    data['filmfest_offset']=data['offset'].apply(lambda x:x+movie_start[film])\n",
    "    data['filmfest_onset']=data['filmfest_offset'].apply(lambda x: x-10 if x>(10+movie_start[film]) else movie_start[film])\n",
    "    data['filmfest_onset30']=data['filmfest_offset'].apply(lambda x: x-30 if x>(30+movie_start[film]) else movie_start[film])\n",
    "    data['TR_onset']=data[['filmfest_onset']].apply(lambda x: seconds_to_tr(x,prediction=False),axis=1)\n",
    "    data['TR_onset30']=data[['filmfest_onset30']].apply(lambda x: seconds_to_tr(x,prediction=False),axis=1)\n",
    "    data['TR_offset']=data['filmfest_offset'].apply(lambda x: seconds_to_tr(x,onset=False))\n",
    "    output_path=f'{folder}/{film}_consensus_mapped_to_neuro.csv'\n",
    "    data.to_csv(output_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b598c65-ce81-4d24-87d2-f100fc0e85cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
