{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c6d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5c60f-55f0-46f3-8bce-7031e2bd7c7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## create LIWC summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "259c42f4-3be7-4310-bff1-1bfd26171979",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ls=['theshoe','therock','theboyfriend','keithreynolds','cmiyc_long','busstop']\n",
    "for film in film_ls:\n",
    "    folder=f'../../Analysis Data/Prediction'\n",
    "    df=pd.read_csv(f'{folder}/{film}_consensus_mapped_to_neuro.csv')\n",
    "\n",
    "    df_LIWC = pd.read_csv(f'../../Analysis Data/LIWC/{film}_prediction_cleaned_LIWC22.csv')\n",
    "    df_LIWC = df_LIWC[df_LIWC['phase_type']=='test']\n",
    "    df_LIWC = df_LIWC[df_LIWC['prediction_number']==1]\n",
    "    all_categories=df_LIWC.columns\n",
    "    all_categories=all_categories[16:]\n",
    "    LIWC_data=df_LIWC.groupby(['video_segment','counterbalance'])[all_categories].mean().reset_index()\n",
    "    LIWC_data[['video_segment', 'counterbalance']] = LIWC_data[['video_segment', 'counterbalance']].astype(int)\n",
    "    result=pd.merge(df, LIWC_data, on=['video_segment','counterbalance'], how='outer')\n",
    "    result=result.rename(columns={'WC':'prediction_wc'})\n",
    "\n",
    "    result.to_csv(f'../../Analysis Data/summary_files/LIWC/'+film+'_prediction_LIWC_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc2effdf-7611-4a2c-9c4b-23af14020564",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ls=['theshoe','therock','theboyfriend','keithreynolds','cmiyc_long','busstop']\n",
    "for film in film_ls:\n",
    "    folder=f'../../Analysis Data/Description'\n",
    "    df=pd.read_csv(f'{folder}/{film}_consensus_mapped_to_neuro.csv')\n",
    "\n",
    "    df_LIWC = pd.read_csv(f'../../Analysis Data/LIWC/{film}_description_cleaned_LIWC22.csv')\n",
    "    df_LIWC = df_LIWC[df_LIWC['phase_type']=='test']\n",
    "    all_categories=df_LIWC.columns\n",
    "    all_categories=all_categories[18:]\n",
    "    LIWC_data=df_LIWC.groupby(['description_stop','counterbalance'])[all_categories].mean().reset_index()\n",
    "    LIWC_data[['description_stop', 'counterbalance']] = LIWC_data[['description_stop', 'counterbalance']].astype(int)\n",
    "    result=pd.merge(df, LIWC_data, on=['description_stop','counterbalance'], how='outer')\n",
    "    result=result.rename(columns={'WC':'description_wc'})\n",
    "\n",
    "    result.to_csv(f'../../Analysis Data/summary_files/LIWC/'+film+'_description_LIWC_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b68316b-7af3-480b-a740-7bfae4c63f02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## create valence and arousal summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e91ec9-0703-449e-b139-fd8de6a6ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "begintime_ls = {\n",
    "    'cmiyc_long': 40,\n",
    "    'theshoe': 999,\n",
    "    'keithreynolds': 1134,\n",
    "    'busstop': 948,\n",
    "    'theboyfriend': 528,\n",
    "    'therock': 40\n",
    "}\n",
    "\n",
    "def split_into_bins(row, begin_time):\n",
    "    start_time = row['start']\n",
    "    end_time = row['end']\n",
    "    bin_size = 10\n",
    "    \n",
    "    # Adjust start and end times relative to the begin_time\n",
    "    adjusted_start = start_time - begin_time\n",
    "    adjusted_end = end_time - begin_time\n",
    "    \n",
    "    start_bin = (adjusted_start // bin_size) * bin_size\n",
    "    end_bin = (adjusted_end // bin_size) * bin_size\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if start_bin == end_bin:\n",
    "        # If the entire row falls within one bin\n",
    "        duration = end_time - start_time\n",
    "        results.append({\n",
    "            'bin': start_bin,\n",
    "            'duration': duration,\n",
    "            'arousal_duration': duration if not np.isnan(row['Arousal_avg']) else 0,\n",
    "            'arousal_weighted': row['Arousal_avg'] * duration if not np.isnan(row['Arousal_avg']) else 0,\n",
    "            'valence_merged': row['valence_merged']\n",
    "        })\n",
    "    else:\n",
    "        # If the row spans two bins\n",
    "        first_bin_end = begin_time + start_bin + bin_size\n",
    "        first_bin_duration = first_bin_end - start_time\n",
    "        second_bin_duration = end_time - first_bin_end\n",
    "        \n",
    "        results.append({\n",
    "            'bin': start_bin,\n",
    "            'duration': first_bin_duration,\n",
    "            'arousal_duration': first_bin_duration if not np.isnan(row['Arousal_avg']) else 0,\n",
    "            'arousal_weighted': row['Arousal_avg'] * first_bin_duration if not np.isnan(row['Arousal_avg']) else 0,\n",
    "            'valence_merged': row['valence_merged']\n",
    "        })\n",
    "        results.append({\n",
    "            'bin': end_bin,\n",
    "            'duration': second_bin_duration,\n",
    "            'arousal_duration': second_bin_duration if not np.isnan(row['Arousal_avg']) else 0,\n",
    "            'arousal_weighted': row['Arousal_avg'] * second_bin_duration if not np.isnan(row['Arousal_avg']) else 0,\n",
    "            'valence_merged': row['valence_merged']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def determine_valence(row):\n",
    "    if row['pos_percent'] > 50:\n",
    "        return 'pos'\n",
    "    elif row['neg_percent'] > 50:\n",
    "        return 'neg'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def process_data_for_bins(current, film_name):\n",
    "    begin_time = begintime_ls[film_name]\n",
    "    \n",
    "    # Apply the function to split rows and create a new dataframe\n",
    "    split_data = current.apply(lambda row: split_into_bins(row, begin_time), axis=1).explode().apply(pd.Series)\n",
    "    \n",
    "    # Group by bin for arousal calculations\n",
    "    arousal_data = split_data.groupby('bin').agg({\n",
    "        'arousal_duration': 'sum',\n",
    "        'arousal_weighted': 'sum'\n",
    "    })\n",
    "    arousal_data['arousal_avg'] = arousal_data['arousal_weighted'] / arousal_data['arousal_duration']\n",
    "    \n",
    "    # Group by bin and valence for valence calculations\n",
    "    valence_data = split_data.groupby(['bin', 'valence_merged'])['duration'].sum().unstack(fill_value=0)\n",
    "    \n",
    "    # Ensure all valence categories exist\n",
    "    for category in ['pos', 'neg', 'neutral']:\n",
    "        if category not in valence_data.columns:\n",
    "            valence_data[category] = 0\n",
    "    \n",
    "    # Calculate total duration and percentages for each valence category\n",
    "    valence_data['total'] = valence_data['pos'] + valence_data['neg'] + valence_data['neutral']\n",
    "    for category in ['pos', 'neg', 'neutral']:\n",
    "        valence_data[f'{category}_percent'] = valence_data[category] / valence_data['total'] * 100\n",
    "    \n",
    "    valence_data['valence_binned'] = valence_data.apply(determine_valence, axis=1)\n",
    "    \n",
    "    # Combine arousal and valence data\n",
    "    combined_data = pd.concat([arousal_data, valence_data], axis=1).reset_index()\n",
    "    \n",
    "    # Adjust bin values back to original timeline\n",
    "    combined_data['bin'] = combined_data['bin'] + begin_time\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91f7093e-51a1-491f-9b6d-51d8a786e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_name={'theshoe':'5. The Shoe','therock':'8. The Rock','theboyfriend':'4. The Boyfriend','keithreynolds':'6. Keith Reynolds','cmiyc_long':'2. Catch Me If You Can','busstop':'12. Bus Stop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c78c44e-e192-46c2-b50e-f6ce550fd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ls=['theshoe','therock','theboyfriend','keithreynolds','cmiyc_long','busstop']\n",
    "data=pd.read_csv('../../Analysis Data/behavior_measurements/valence_arousal_summary.csv')\n",
    "\n",
    "for film in film_ls:\n",
    "    folder=f'../../Analysis Data/Prediction'\n",
    "    df=pd.read_csv(f'{folder}/{film}_consensus_mapped_to_neuro.csv')\n",
    "    \n",
    "    current = data[data['SEG-12 title']==film_name[film]].copy()\n",
    "    def convert_to_seconds(value):\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        minutes, seconds = divmod(value, 1)\n",
    "        seconds *= 100  # Convert decimal part to actual seconds\n",
    "        return int(minutes * 60 + round(seconds))\n",
    "    current.loc[:,'start']=current['SEG-1000 Start Time (m.ss)'].apply(convert_to_seconds)\n",
    "    current.loc[:,'end']=current['SEG-1000 End Time (m.ss)'].apply(convert_to_seconds)\n",
    "    \n",
    "    combined_data = process_data_for_bins(current,film)\n",
    "    combined_data.loc[:,'bin_end']=combined_data['bin']+10\n",
    "    merge_data=combined_data[['bin_end','arousal_avg','valence_binned']]\n",
    "    final=df.merge(merge_data,left_on='filmfest_offset',right_on='bin_end',how='left')\n",
    "    final['valence'] = final['valence_binned'].apply(lambda x: 1 if x=='pos' else (-1 if x=='neg' else 0))\n",
    "    final.to_csv('../../Analysis Data/summary_files/valence_arousal/'+film+'_valence_arousal_summary.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
